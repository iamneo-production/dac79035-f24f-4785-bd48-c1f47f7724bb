# -*- coding: utf-8 -*-
"""AQI_PREDICTION.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1O8Ds3bSJcX-MWIqveuz4k0Dgk6ZTt_ca
"""

import pandas as pd
abc=pd.read_csv('/home/coder/project/workspace/NASCOM_CHANLLANGE/AQI_PREDICTION_MODEL+DATA/okay.csv')

abc.columns

abc=abc.drop(['Sampling Location.1','Sampling Location.2','Station Name'], axis=1)
abc=abc.drop(['Location'], axis=1)

dataset1=abc[['S.NO','Sampling Location','Jan-22','Jan-22.1','Jan-22.2','Jan-22.3','Jan-22.4']]
dataset2=abc[['S.NO','Sampling Location','Feb-22','Feb-22.1','Feb-22.2','Feb-22.3','Feb-22.4']]
dataset3=abc[['S.NO','Sampling Location','Mar-22','Mar-22.1','Mar-22.2','Mar-22.3','Mar-22.4']]
dataset4=abc[['S.NO','Sampling Location','Apr-22','Apr-22.1','Apr-22.2','Apr-22.3','Apr-22.4']]
dataset5=abc[['S.NO','Sampling Location','May-22','May-22.1','May-22.2','May-22.3','May-22.4']]
dataset6=abc[['S.NO','Sampling Location','Jun-22','Jun-22.1','Jun-22.2','Jun-22.3','Jun-22.4']]
dataset7=abc[['S.NO','Sampling Location','Jul-22','Jul-22.1','Jul-22.2','Jul-22.3','Jul-22.4']]
dataset8=abc[['S.NO','Sampling Location','Aug-22','Aug-22.1','Aug-22.2','Aug-22.3','Aug-22.4']]
dataset9=abc[['S.NO','Sampling Location','Sep-22','Sep-22.1','Sep-22.2','Sep-22.3','Sep-22.4']]
dataset10=abc[['S.NO','Sampling Location','Oct-22','Oct-22.1','Oct-22.2','Oct-22.3','Oct-22.4']]
dataset11=abc[['S.NO','Sampling Location','Nov-22','Nov-22.1','Nov-22.2','Nov-22.3','Nov-22.4']]
dataset12=abc[['S.NO','Sampling Location','Dec-22','Dec-22.1','Dec-22.2','Dec-22.3','Dec-22.4']]

dataset1.set_axis(['S.NO','Sampling Location','SO2','NO2','PM10','NH3','AQI'], axis='columns', inplace=True)
dataset2.set_axis(['S.NO','Sampling Location','SO2','NO2','PM10','NH3','AQI'], axis='columns', inplace=True)
dataset3.set_axis(['S.NO','Sampling Location','SO2','NO2','PM10','NH3','AQI'], axis='columns', inplace=True)
dataset4.set_axis(['S.NO','Sampling Location','SO2','NO2','PM10','NH3','AQI'], axis='columns', inplace=True)
dataset5.set_axis(['S.NO','Sampling Location','SO2','NO2','PM10','NH3','AQI'], axis='columns', inplace=True)
dataset6.set_axis(['S.NO','Sampling Location','SO2','NO2','PM10','NH3','AQI'], axis='columns', inplace=True)
dataset7.set_axis(['S.NO','Sampling Location','SO2','NO2','PM10','NH3','AQI'], axis='columns', inplace=True)
dataset8.set_axis(['S.NO','Sampling Location','SO2','NO2','PM10','NH3','AQI'], axis='columns', inplace=True)
dataset9.set_axis(['S.NO','Sampling Location','SO2','NO2','PM10','NH3','AQI'], axis='columns', inplace=True)
dataset10.set_axis(['S.NO','Sampling Location','SO2','NO2','PM10','NH3','AQI'], axis='columns', inplace=True)
dataset11.set_axis(['S.NO','Sampling Location','SO2','NO2','PM10','NH3','AQI'], axis='columns', inplace=True)
dataset12.set_axis(['S.NO','Sampling Location','SO2','NO2','PM10','NH3','AQI'], axis='columns', inplace=True)

concatenated = pd.concat([dataset1, dataset2,dataset3,dataset4,dataset5,dataset6,dataset7,dataset8,dataset9,dataset10,dataset11,dataset12])

concatenated['Sampling Location'] =  concatenated['Sampling Location'].fillna('locn_unknown')

concatenated['SO2'] = concatenated['SO2'].replace(["Commenced from April","-","< 4","BDL","Ins. Repair","<4"], [0,0,3.9,0,0,3.9])
concatenated["SO2"] = pd.to_numeric(concatenated["SO2"], downcast="float")
concatenated["SO2"] = concatenated['SO2'].fillna(concatenated['SO2'].mean())

concatenated['NO2'] = concatenated['NO2'].replace(["Commenced from April","-","< 4","BDL","Ins. Repair","<4"], [0,0,3.9,0,0,3.9])
concatenated["NO2"] = pd.to_numeric(concatenated["NO2"], downcast="float")
concatenated["NO2"] = concatenated['NO2'].fillna(concatenated['NO2'].mean())

concatenated['AQI'] = concatenated['AQI'].replace(["No Data","Commenced from April","-","< 4","BDL","Ins. Repair","<4"], [0,0,0,3.9,0,0,3.9])
concatenated["AQI"] = pd.to_numeric(concatenated["AQI"], downcast="float")
concatenated["AQI"] = concatenated['AQI'].fillna(concatenated['AQI'].mean())

concatenated['PM10'] = concatenated['PM10'].replace(["No Data","Commenced from April","-","< 4","BDL","Ins. Repair","<4"], [0,0,0,3.9,0,0,3.9])
concatenated["PM10"] = pd.to_numeric(concatenated["PM10"], downcast="float")
concatenated["PM10"] = concatenated['PM10'].fillna(concatenated['PM10'].mean())



concatenated.info()

concatenated=concatenated.drop(['S.NO'], axis=1)

concatenated=concatenated.dropna()

concatenated.isnull().sum()/4140 *100

concatenated['NH3'] = concatenated['NH3'].replace(["Ammonia (NH3) for SAAQM stations Started from June","No Data","Commenced from April","-","< 4","BDL","Ins. Repair","<4"], [0,0,0,0,3.9,0,0,3.9])
concatenated["NH3"] = pd.to_numeric(concatenated["NH3"], downcast="float")
concatenated["NH3"] = concatenated['NH3'].fillna(concatenated['NH3'].mean())

concatenated.info()

concatenated.shape

ans=concatenated[(concatenated.SO2 != 0) & (concatenated.NO2 != 0)&(concatenated.PM10 != 0)&(concatenated.NH3 != 0)&(concatenated.AQI != 0)]

ans.shape

# Checking for outliers in the continuous variables
num_ans = ans[['SO2','NO2','NH3','PM10']]

# Checking outliers at 25%, 50%, 75%, 90%, 95% and 99%
num_ans.describe(percentiles=[.25, .5, .75, .90, .95, .99])

from sklearn.model_selection import train_test_split
# Putting feature variable to X
X = ans.drop(['AQI','Sampling Location'], axis=1)

X.head()

# Putting response variable to y
y = ans['AQI']

y.head()

# Splitting the data into train and test
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)

# Commented out IPython magic to ensure Python compatibility.
# Importing matplotlib and seaborn
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
# Let's see the correlation matrix 
plt.figure(figsize = (20,10))        # Size of the figure
sns.heatmap(ans.corr(),annot = True)
plt.show()

from sklearn.linear_model import LinearRegression
regr = LinearRegression()
model=regr.fit(X_train, y_train)
print(regr.score(X_test, y_test))

from sklearn.metrics import mean_absolute_error,mean_squared_error
y_pred = regr.predict(X_test) 
mae = mean_absolute_error(y_true=y_test,y_pred=y_pred)
#squared True returns MSE value, False returns RMSE value.
mse = mean_squared_error(y_true=y_test,y_pred=y_pred) #default=True
rmse = mean_squared_error(y_true=y_test,y_pred=y_pred,squared=False)
  
print("MAE:",mae)
print("MSE:",mse)
print("RMSE:",rmse)

from xgboost import XGBRegressor
RegModel=XGBRegressor(max_depth=3, learning_rate=0.1, n_estimators=500, objective='reg:linear', booster='gbtree')
 
#Printing all the parameters of XGBoost
print(RegModel)
 
#Creating the model on Training Data
XGB=RegModel.fit(X_train,y_train)
prediction=XGB.predict(X_test)
 
#Measuring Goodness of fit in Training data
from sklearn import metrics
print('R2 Value:',metrics.r2_score(y_train, XGB.predict(X_train)))
 
#Measuring accuracy on Testing Data
import numpy as np
print('Accuracy',100- (np.mean(np.abs((y_test - prediction) / y_test)) * 100))

mae = mean_absolute_error(y_true=y_test,y_pred=prediction)
#squared True returns MSE value, False returns RMSE value.
mse = mean_squared_error(y_true=y_test,y_pred=prediction) #default=True
rmse = mean_squared_error(y_true=y_test,y_pred=prediction,squared=False)
  
print("MAE:",mae)
print("MSE:",mse)
print("RMSE:",rmse)

# Installing required libraries
!pip install tensorflow
!pip install keras

# importing the libraries
from keras.models import Sequential
from keras.layers import Dense

# create ANN model
model = Sequential()

# Defining the Input layer and FIRST hidden layer, both are same!
model.add(Dense(units=5, input_dim=4, kernel_initializer='normal', activation='relu'))

# Defining the Second layer of the model
# after the first layer we don't have to specify input_dim as keras configure it automatically
model.add(Dense(units=5, kernel_initializer='normal', activation='tanh'))

# The output neuron is a single fully connected node 
# Since we will be predicting a single number
model.add(Dense(1, kernel_initializer='normal'))

# Compiling the model
model.compile(loss='mean_squared_error', optimizer='adam')

# Fitting the ANN to the Training set
model.fit(X_train, y_train ,batch_size = 20, epochs = 50, verbose=1)

# Fitting the ANN to the Training set
model.fit(X_train, y_train ,batch_size = 15, epochs = 5, verbose=0)
 
# Generating Predictions on testing data
ann_Predictions=model.predict(X_test)

mae = mean_absolute_error(y_true=y_test,y_pred=ann_Predictions)
#squared True returns MSE value, False returns RMSE value.
mse = mean_squared_error(y_true=y_test,y_pred=ann_Predictions) #default=True
rmse = mean_squared_error(y_true=y_test,y_pred=ann_Predictions,squared=False)
  
print("MAE:",mae)
print("MSE:",mse)
print("RMSE:",rmse)

from keras.callbacks import ModelCheckpoint
from keras.models import Sequential
from keras.layers import Dense, Activation, Flatten
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error 
from matplotlib import pyplot as plt
import seaborn as sb
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import warnings 
warnings.filterwarnings('ignore')
warnings.filterwarnings('ignore', category=DeprecationWarning)
from xgboost import XGBRegressor

NN_model = Sequential()

# The Input Layer :
NN_model.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))
# The Hidden Layers :
NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))
NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))
NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))
# The Output Layer :
NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))

# Compile the network :
NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])
NN_model.summary()

checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' 
checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')
callbacks_list = [checkpoint]

NN_model.fit(X_train,y_train, epochs=600, batch_size=60, validation_split = 0.5, callbacks=callbacks_list)

# Generating Predictions on testing data
ann2_Predictions=NN_model.predict(X_test)

mae = mean_absolute_error(y_true=y_test,y_pred=ann2_Predictions)
#squared True returns MSE value, False returns RMSE value.
mse = mean_squared_error(y_true=y_test,y_pred=ann2_Predictions) #default=True
rmse = mean_squared_error(y_true=y_test,y_pred=ann2_Predictions,squared=False)
print("MAE:",mae)
print("MSE:",mse)
print("RMSE:",rmse)

import xgboost as xgb
# xgboost regressor
model_xgb = xgb.XGBRegressor()
# training the model
model_xgb.fit(X_train,y_train)

model_pred_xgb = model_xgb.predict(X_test)

#importing the r-square score
from sklearn.metrics import r2_score
# calculating the r score 
print('R score is :', r2_score(y_test, model_pred_xgb))

mae = mean_absolute_error(y_true=y_test,y_pred= model_pred_xgb)
#squared True returns MSE value, False returns RMSE value.
mse = mean_squared_error(y_true=y_test,y_pred= model_pred_xgb) #default=True
rmse = mean_squared_error(y_true=y_test,y_pred= model_pred_xgb,squared=False)
print("MAE:",mae)
print("MSE:",mse)
print("RMSE:",rmse)

"""PREDICTIONS
NALGONDA (SO2)
"""

temps = [11.5, 15.5, 17.5, 19.8, 18.1, 15.1, 12.5, 15.6, 17, 18.8, 13.5, 15.5]

# increase all temperature values by 5%
temps = [temp * 1.05 for temp in temps]

# print the new temperature values
print(temps)

TEMPS=[26.3,
28.5,
32.5,
33.6,
32.4,
32.5,
31.5,
35.3,
37.0,
37.2,
33.6,
34.8,
]
# increase all temperature values by 5%
temps = [temp * 1.05 for temp in temps]

# print the new temperature values
print(temps)

temps=[85,
89,
96,
98,
97,
92,
81,
84,
88,
93,
87,
89]

# increase all temperature values by 5%
temps = [temp * 1.05 for temp in temps]

# print the new temperature values
print(temps)

temps=[20,
23,
25,
26,
27,
23,
22,
22,
24,
24,
23,
23,

]
# increase all temperature values by 5%
temps = [temp * 1.05 for temp in temps]

# print the new temperature values
print(temps)

import numpy as np

input_values = [
    [12.075, 12.678, 89.25, 21],
    [16.275, 17.088, 93.45, 24.15],
    [18.375, 19.29375, 100.8, 26.25],
    [20.79, 21.8295, 102.9, 27.3],
    [19.005, 19.95525, 101.85, 28.35],
    [15.855, 16.64775, 96.6, 24.15],
    [13.125, 13.78125, 85.05, 23.1],
    [16.38, 17.199, 88.2, 23.1],
    [17.85, 18.7425, 92.4, 25.2],
    [19.74, 20.727, 97.65, 25.2],
    [14.175, 14.88375, 91.35, 24.15],
    [16.275, 17.08875, 93.45, 24.15]
]
# Make a prediction using the trained model
prediction = NN_model.predict(input_values)

# Print the prediction
print(prediction)

"""ADILABAD """

temps=[8,8,
      8.2,
9.5,
7.9,
8.6,
6.8,
8.5,
9.7,
10.9,
7.5,
9.5

]# increase all temperature values by 5%
temps = [temp * 1.05 for temp in temps]

# print the new temperature values
print(temps)

temps=[27,27,25.6,
28.2,
26.5,
25.0,
23.1,
26.2,
27.5,
29.3,
26.4,
25.3

]# increase all temperature values by 5%
temps = [temp * 1.05 for temp in temps]

# print the new temperature values
print(temps)

temps=[50,50,56,
65,
60,
57,
48,
56,
54,
62,
58,
62

]# increase all temperature values by 5%
temps = [temp * 1.05 for temp in temps]

# print the new temperature values
print(temps)

temps=[15,15,14,
18,
14,
16,
15,
17,
19,
21,
18,
20

]# increase all temperature values by 5%
temps = [temp * 1.05 for temp in temps]

# print the new temperature values
print(temps)

input_values = [
    [8.4, 28.35, 52.5, 15.75], [8.4, 28.35, 52.5, 15.75], [8.61, 26.88, 58.8, 14.7], [9.975, 29.61, 68.25, 18.9], [8.295, 27.825, 63.0, 14.7], [9.03, 26.25, 59.85, 16.8], [7.14, 24.255, 50.4, 15.75], [8.925, 27.51, 58.8, 17.85], [10.185, 28.875, 56.7, 19.95], [11.445, 30.765, 65.1, 22.05], [7.875, 27.72, 60.9, 18.9], [9.975, 26.565, 65.1, 21.0]

]
# Make a prediction using the trained model
prediction = NN_model.predict(input_values)

# Print the prediction
print(prediction)

"""KARIMNAGAR"""

temps=[7.8,
6.4,
6.8,
8.0,
6.3,
6.4,
7.0,
6.0,
6.7,
6.7,
6.2,
6.2

]# increase all temperature values by 5%
temps = [temp * 1.05 for temp in temps]

# print the new temperature values
print(temps)

temps=[30.3,
27.9,
26.7,
28.4,
26.8,
32.0,
29.3,
27.4,
29.9,
30.6,
26.1,
32.7

]# increase all temperature values by 5%
temps = [temp * 1.05 for temp in temps]

# print the new temperature values
print(temps)

temps=[82,
92,
99,
70,
78,
92,
69,
55,
58,
62,
103,
139

]# increase all temperature values by 5%
temps = [temp * 1.05 for temp in temps]

# print the new temperature values
print(temps)

temps=[32,
22,
23,
24,
20,
31,
33,
19,
20,
29,
22,
35

]# increase all temperature values by 5%
temps = [temp * 1.05 for temp in temps]

# print the new temperature values
print(temps)

input_values=[[8.19, 31.815, 86.1, 33.6],
[6.72, 29.295, 96.6, 23.1],
[7.14, 28.035, 103.95, 24.15],
[8.4, 29.82, 73.5, 25.2],
[6.615, 28.14, 81.9, 21.0],
[6.72, 33.6, 96.6, 32.55],
[7.35, 30.765, 72.45, 34.65],
[6.3, 28.77, 57.75, 19.95],
[7.035, 31.395, 60.9, 21.0],
[7.035, 32.13, 65.1, 30.45],
[6.51, 27.405, 108.15, 23.1],
[6.51, 34.335, 145.95, 36.75]]
# Make a prediction using the trained model
prediction = NN_model.predict(input_values)

# Print the predict
print(prediction)

"""KHAMMAM"""

temps=[6.8,
7.6,
7.8,
7.3,
7.1,
7.4,
7.4,
7.4,
7.0,
7.4,
8.0,
7.1

]# increase all temperature values by 5%
temps = [temp * 1.05 for temp in temps]

# print the new temperature values
print(temps)

temps=[29.8,
30.7,
51.5,
44.6,
41.0,
45.4,
45.6,
41.5,
31.2,
30.9,
30.0,
29.1

]# increase all temperature values by 5%
temps = [temp * 1.05 for temp in temps]

# print the new temperature values
print(temps)

temps=[80,
78,
76,
78,
77,
81,
73,
56,
41,
57,
78,
112

]# increase all temperature values by 5%
temps = [temp * 1.05 for temp in temps]

# print the new temperature values
print(temps)

temps=[45,
48,
65,
65,
66,
67,
62,
44,
38,
39,
35,
33

]# increase all temperature values by 5%
temps = [temp * 1.05 for temp in temps]

# print the new temperature values
print(temps)

import numpy as np

array1 = [7.14, 7.9799999999999995, 8.19, 7.665, 7.455, 7.7700000000000005, 7.7700000000000005, 7.7700000000000005, 7.3500000000000005, 7.7700000000000005, 8.4, 7.455]
array2 = [31.290000000000003, 32.235, 54.075, 46.830000000000005, 43.050000000000004, 47.67, 47.88, 43.575, 32.76, 32.445, 31.5, 30.555000000000003]
array3 = [84.0, 81.9, 79.8, 81.9, 80.85000000000001, 85.05, 76.65, 58.800000000000004, 43.050000000000004, 59.85, 81.9, 117.60000000000001]
array4 = [47.25, 50.400000000000006, 68.25, 68.25, 69.3, 70.35000000000001, 65.10000000000001, 46.2, 39.9, 40.95, 36.75, 34.65]

arrays = np.vstack([array1, array2, array3, array4])
input_values = arrays.T.reshape(12, 4)


# Make a prediction using the trained model
prediction = NN_model.predict(input_values)

# Print the predic
print(prediction)

"""NIZAMABAD"""

temps=[6.9,
7.5,
6.6,
7.8,
7.3,
6.0,
5.5,
6.7,
7.9,
8.6,
6.8,
7.5

]# increase all temperature values by 5%
temps = [temp * 1.05 for temp in temps]

# print the new temperature values
print(temps)

temps=[25.5,
27.5,
26.1,
24.0,
24.6,
23.4,
21.3,
23.3,
25.0,
27.4,
25.0,
22.6

]# increase all temperature values by 5%
temps = [temp * 1.05 for temp in temps]

# print the new temperature values
print(temps)

temps=[56,
59,
64,
58,
56,
52,
46,
52,
51,
61,
56,
60

]# increase all temperature values by 5%
temps = [temp * 1.05 for temp in temps]

# print the new temperature values
print(temps)

temps=[14,
15,
17,
16,
14,
15,
13,
14,
16,
18,
16,
17

]# increase all temperature values by 5%
temps = [temp * 1.05 for temp in temps]

# print the new temperature values
print(temps)

array1 = [7.245000000000001, 7.875, 6.93, 8.19, 7.665, 6.300000000000001, 5.775, 7.035, 8.295, 9.03, 7.14, 7.875]
array2 = [26.775000000000002, 28.875, 27.405, 25.200000000000003, 25.830000000000002, 24.57, 22.365000000000002, 24.465000000000003, 26.25, 28.77, 26.25, 23.730000000000004]
array3 = [58.800000000000004, 61.95, 67.2, 60.900000000000006, 58.800000000000004, 54.6, 48.300000000000004, 54.6, 53.550000000000004, 64.05, 58.800000000000004, 63.0]
array4 = [14.700000000000001, 15.75, 17.85, 16.8, 14.700000000000001, 15.75, 13.65, 14.700000000000001, 16.8, 18.900000000000002, 16.8, 17.85]

arrays = np.vstack([array1, array2, array3, array4])
input_values = arrays.T.reshape(12, 4)

# Make a prediction using the trained model
prediction = NN_model.predict(input_values)

# Print the predict
print(prediction)

"""MAHBOOBNAGAR"""

temps=[8.4,
8.5,
9.2,
8.8,
8.2,
7.4,
8.4,
8.0,
8.1,
7.2,
7.4,
7.4

]# increase all temperature values by 5%
temps = [temp * 1.05 for temp in temps]

# print the new temperature values
print(temps)

temps=[43.7,
45.8,
43.3,
43.8,
45.6,
42.5,
41.0,
39.9,
38.6,
40.4,
42.1,
40.0

]# increase all temperature values by 5%
temps = [temp * 1.05 for temp in temps]

# print the new temperature values
print(temps)

temps=[95,
72,
92,
85,
84,
110,
80,
88,
79,
93,
115,
111

]# increase all temperature values by 5%
temps = [temp * 1.05 for temp in temps]

# print the new temperature values
print(temps)

temps=[39,
42,
40,
43,
42,
39,
40,
28,
30,
41,
40,
41

]# increase all temperature values by 5%
temps = [temp * 1.05 for temp in temps]

# print the new temperature values
print(temps)

array1=[8.82, 8.925, 9.66, 9.240000000000002, 8.61, 7.7700000000000005, 8.82, 8.4, 8.505, 7.5600000000000005, 7.7700000000000005, 7.7700000000000005]
array2=[45.885000000000005, 48.089999999999996, 45.464999999999996, 45.99, 47.88, 44.625, 43.050000000000004, 41.895, 40.53, 42.42, 44.205000000000005, 42.0]
array3=[99.75, 75.60000000000001, 96.60000000000001, 89.25, 88.2, 115.5, 84.0, 92.4, 82.95, 97.65, 120.75, 116.55000000000001]
array4=[40.95, 44.1, 42.0, 45.15, 44.1, 40.95, 42.0, 29.400000000000002, 31.5, 43.050000000000004, 42.0, 43.050000000000004]
arrays = np.vstack([array1, array2, array3, array4])
input_values = arrays.T.reshape(12, 4)
# Make a prediction using the trained model
prediction = NN_model.predict(input_values)

# Print the predict
print(prediction)

"""WARANGAL"""

temps=[7.1,
8.4,
8.0,
7.6,
7.8,
7.5,
7.2,
6.5,
7.1,
7.9,
7.6,
8.3

]# increase all temperature values by 5%
temps = [temp * 1.05 for temp in temps]

# print the new temperature values
print(temps)

temps=[31.8,
31.0,
33.1,
34.2,
34.2,
34.7,
30.2,
26.6,
29.9,
32.2,
35.0,
32.6



]# increase all temperature values by 5%
temps = [temp * 1.05 for temp in temps]

# print the new temperature values
print(temps)

temps=[73,
73,
76,
60,
77,
85,
47,
56,
48,
63,
95,
95

]# increase all temperature values by 5%
temps = [temp * 1.05 for temp in temps]

# print the new temperature values
print(temps)

temps=[36,
49,
39,
40,
40,
39,
36,
23,
27,
39,
37,
35

]# increase all temperature values by 5%
temps = [temp * 1.05 for temp in temps]

# print the new temperature values
print(temps)

array1=[7.455, 8.82, 8.4, 7.9799999999999995, 8.19, 7.875, 7.5600000000000005, 6.825, 7.455, 8.295, 7.9799999999999995, 8.715000000000002]
array2=[33.39, 32.550000000000004, 34.755, 35.910000000000004, 35.910000000000004, 36.435, 31.71, 27.930000000000003, 31.395, 33.81, 36.75, 34.230000000000004]
array3=[76.65, 76.65, 79.8, 63.0, 80.85000000000001, 89.25, 49.35, 58.800000000000004, 50.400000000000006, 66.15, 99.75, 99.75]
array4=[37.800000000000004, 51.45, 40.95, 42.0, 42.0, 40.95, 37.800000000000004, 24.150000000000002, 28.35, 40.95, 38.85, 36.75]
arrays = np.vstack([array1, array2, array3, array4])
input_values = arrays.T.reshape(12, 4)
# Make a prediction using the trained model
prediction = NN_model.predict(input_values)

# Print the predict
print(prediction)